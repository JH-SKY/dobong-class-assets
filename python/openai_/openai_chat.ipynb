{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Chat Completions API\n",
    "https://platform.openai.com/docs/overview  \n",
    "https://platform.openai.com/docs/api-reference/chat  \n",
    "\n",
    "배포된 openai의 api key를 .env의 OPENAI_API_KEY에 등록하여 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "URL = \"https://api.openai.com/v1/chat/completions\"\n",
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST API 요청\n",
    "라이브러리 없이 직접 HTTP 통신을 통해 api를 호출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Completions API는 사용자가 입력한 텍스트에 기반하여 이어지는 대화를 생성하는 인공지능 API입니다. 이를 통해 자연스러운 대화 흐름을 유지하면서 다양한 주제에 대해 상호작용할 수 있습니다. 이 API는 챗봇, 고객 지원 및 다양한 애플리케이션에서 활용됩니다.\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {OPENAI_API_KEY}\"\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": model,\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"당신은 친절한 AI 강사입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Chat Completions API가 뭐야? 2~3문장으로 답변해줘\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "response = requests.post(URL, headers=headers, json=payload)\n",
    "#pprint(response.json())\n",
    "print(response.json()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI SDK를 활용한 요청\n",
    "공식 라이브러리를 사용하여 생산성을 높이는 표준 방식이다.  \n",
    "`pip install openai` 를 통해 설치한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI SDK를 사용하면 여러 가지 장점이 있습니다. 이를 통해 개발자와 기업은 다양한 AI 기능을 쉽게 통합하고 활용할 수 있습니다. 주요 장점을 몇 가지 소개하겠습니다.\n",
      "\n",
      "1. **사용 용이성**: OpenAI SDK는 직관적이고 사용이 간편한 인터페이스를 제공하여, 개발자가 복잡한 AI 모델을 쉽게 사용할 수 있게 합니다. API 호출을 통해 손쉽게 기능을 구현할 수 있습니다.\n",
      "\n",
      "2. **강력한 성능**: OpenAI의 모델은 자연어 처리와 생성에 있어 높은 성능을 보여줍니다. 이는 고객 지원, 콘텐츠 생성, 코드 작성, 데이터 분석 등 다양한 분야에서 활용 가능하게 합니다.\n",
      "\n",
      "3. **커스터마이징**: OpenAI의 API를 통해 사용자는 특정한 요구에 맞게 모델을 조정하거나 파인튜닝할 수 있어, 더 나은 결과를 도출할 수 있습니다.\n",
      "\n",
      "4. **다양한 기능**: 텍스트 생성, 번역, 요약, 질문답변 등 여러 가지 언어 처리 작업을 지원하여, 다양한 애플리케이션에서 활용할 수 있습니다.\n",
      "\n",
      "5. **지속적인 업데이트**: OpenAI는 지속적으로 모델을 개선하고 업데이트하여 최신의 성능을 유지합니다. 새로운 기능이나 향상된 모델이 지속적으로 제공됩니다.\n",
      "\n",
      "6. **커뮤니티와 지원**: OpenAI의 SDK를 사용하는 개발자 커뮤니티가 활성화되어 있어, 질문이나 문제 발생 시 다양한 지원을 받을 수 있습니다.\n",
      "\n",
      "7. **비용 효율성**: 자체적으로 AI 모델을 구축하고 유지하는 것보다 OpenAI API를 사용하는 것이 비용과 시간을 절약할 수 있습니다. 필요한 경우에만 사용할 수 있는 유연한 요금제를 제공하기 때문입니다.\n",
      "\n",
      "이러한 장점 덕분에 OpenAI SDK는 많은 기업과 개발자에게 유용한 도구로 자리 잡고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Openai SDK를 사용하면 어떤 점이 좋아?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Prompt 비교\n",
    "\n",
    "동일한 질문에 대해 AI의 페르소나에 따라 답변이 어떻게 달라지는지 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"아침 일찍 일어나는 습관의 장점에 대해 말해줘.\"\n",
    "\n",
    "personas = {\n",
    "    \"열정적인 셰프\": \"당신은 요리에 인생을 건 셰프입니다. 인생의 모든 이치를 요리 과정과 재료에 비유하여 설명하세요.\",\n",
    "    \"엄격한 헬스 트레이너\": \"당신은 매우 엄격한 운동 전문가입니다. 강한 어조로 자기관리를 강조하며 답변하세요.\",\n",
    "    \"지혜로운 판다\": \"당신은 대나무 숲에 사는 느긋하고 지혜로운 판다입니다. 느릿느릿하고 평화로운 말투로 조언을 건네세요.\"\n",
    "}\n",
    "\n",
    "for name, prompt in personas.items():\n",
    "    print(f\"--- [{name}] 버전 ---\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature 비교\n",
    "\n",
    "동일한 질문에 대해 temperature에 따라 답변이 어떻게 달라지는지 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_topic = \"운동화 브랜드의 새로운 슬로건을 5개 제안해줘. 단, '속도'나 '승리' 같은 뻔한 단어는 제외하고 아주 기발하게 작성해줘.\"\n",
    "temperatures = [0.3, 0.8, 1.0, 1.3, 1.5, 1.6, 1.8]\n",
    "\n",
    "for t in temperatures:\n",
    "    print(f\"### 설정값 (Temperature): {t} ###\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": creative_topic}],\n",
    "        temperature=t,\n",
    "        max_completion_tokens=200, \n",
    "        timeout=15.0\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creative_topic = \"우리집 강아지의 별명을 3개 지어줘.\"\n",
    "temperatures = [0.3, 0.8, 1.0, 1.3, 1.5, 1.6, 1.8]\n",
    "\n",
    "for t in temperatures:\n",
    "    print(f\"### 설정값 (Temperature): {t} ###\")\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": creative_topic}],\n",
    "        temperature=t,\n",
    "        max_completion_tokens=200, \n",
    "        timeout=15.0\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `messages` 배열을 활용한 대화 맥락 유지 (Context Window)\n",
    "Chat Completions API는 상태를 저장하지 않는(Stateless) 방식이므로, 이전 대화 내역을 리스트에 계속 누적해서 보내야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_without_memory(user_input):\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # 3. 모델의 답변을 기록에 추가 (이것이 맥락 유지의 핵심)\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# 실습 테스트\n",
    "print(\"Q1: 내 이름은 jun이야.\")\n",
    "print(f\"A1: {chat_without_memory('내 이름은 jun이야')}\\n\")\n",
    "\n",
    "print(\"Q2: 내 이름이 뭐라고?\")\n",
    "print(f\"A2: {chat_without_memory('내 이름이 뭐라고?')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대화 내역을 저장할 리스트 초기화\n",
    "history = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 사용자의 이름을 기억하는 비서입니다.\"}\n",
    "]\n",
    "\n",
    "def chat_with_memory(user_input):\n",
    "    # 1. 사용자 질문을 기록에 추가\n",
    "    history.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    # 2. 전체 기록을 API에 전송\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=history\n",
    "    )\n",
    "    \n",
    "    # 3. 모델의 답변을 기록에 추가 (이것이 맥락 유지의 핵심)\n",
    "    answer = response.choices[0].message.content\n",
    "    history.append({\"role\": \"assistant\", \"content\": answer})\n",
    "    \n",
    "    return answer\n",
    "\n",
    "# 실습 테스트\n",
    "print(\"Q1: 내 이름은 jun이야.\")\n",
    "print(f\"A1: {chat_with_memory('내 이름은 jun이야.')}\\n\")\n",
    "\n",
    "print(\"Q2: 내 이름이 뭐라고?\")\n",
    "print(f\"A2: {chat_with_memory('내 이름이 뭐라고?')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Outputs (구조화된 출력)\n",
    "모델의 답변을 단순히 텍스트로 받는 것이 아니라, JSON 형태로 고정하여 받을 수 있다.  \n",
    "웹 서비스의 백엔드에서 데이터를 바로 처리해야 할 때 필수적인 기능이다.  \n",
    "여기서는 `JSON mode(json_object)`로 json format을 활용하지만,  \n",
    "이후에는 pydantic 라이브러리를 활용한 `JSON Scheme` 방식을 통해 명확한 json 응답 형식을 지정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 요리사야. 답변은 반드시 JSON 형식으로 해줘.\"},\n",
    "        {\"role\": \"user\", \"content\": \"떡볶이 레시피 알려줘.\"}\n",
    "    ],\n",
    "    # JSON 모드 활성화\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "# 문자열로 온 답변을 직접 파싱해야 함\n",
    "res_json = json.loads(response.choices[0].message.content)\n",
    "print(res_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming (실시간 응답 처리)\n",
    "stream=True 설정을 통해 활성화한다.  \n",
    "서버는 SSE(Server-Sent Events) 프로토콜을 사용하여 응답을 끊지 않고 조각(Chunk) 단위로 지속적으로 전송한다.  \n",
    "응답 객체는 제너레이터 형식으로, for 루프를 사용해 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"양자 역학에 대해 초등학생도 이해할 수 있게 설명해줘.\"\n",
    "print(f\"질문: {prompt}\\n\")\n",
    "print(\"답변: \", end=\"\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    stream=True \n",
    ")\n",
    "\n",
    "full_response = \"\"\n",
    "for chunk in response:\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content:\n",
    "        print(content, end=\"\", flush=True) # flush 옵션을 통해 출력 버퍼를 즉시 비워 스트리밍 답변이 지연 없이 실시간으로 표시되도록 한다.\n",
    "        full_response += content\n",
    "\n",
    "print(\"\\n\\n--- 스트리밍 종료 ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비동기 요청\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[서울] 맛집 검색 시작...\n",
      "[파리] 맛집 검색 시작...\n",
      "[뉴욕] 맛집 검색 시작...\n",
      "[도쿄] 맛집 검색 시작...\n",
      "[방콕] 맛집 검색 시작...\n",
      "[로마] 맛집 검색 시작...\n",
      "[뉴욕] 검색 완료!\n",
      "[로마] 검색 완료!\n",
      "[파리] 검색 완료!\n",
      "[방콕] 검색 완료!\n",
      "[서울] 검색 완료!\n",
      "[도쿄] 검색 완료!\n",
      "\n",
      "--- [여행자들을 위한 미식 가이드] ---\n",
      "서울: 서울에 가면 꼭 먹어야 할 음식은 '김치찌개'입니다. 김치찌개는 한국의 대표적인 전통 찌개로, 깊고 얼큰한 국물에 숙성된 김치와 돼지고기 또는 두부를 넣어 끓인 요리입니다. 따뜻한 밥과 함께 먹으면 정말 맛있고, 한국의 얼핏 지친 마음을 따뜻하게 녹여주는 음식이죠. 서울에서 맛있는 김치찌개를 꼭 즐겨보세요!\n",
      "파리: 파리에 간다면 꼭 먹어야 할 음식은 크루아상(Croissant)입니다. 바삭하고 버터 향이 가득한 이 프랑스식 페이스트리는 아침식사로 적합하며, 현지 베이커리에서 갓 구운 크루아상을 즐기면 파리의 맛을 진정으로 느낄 수 있습니다.\n",
      "뉴욕: 뉴욕에 가면 꼭 먹어야 할 음식은 \"슬라이더(Slider)\"입니다. 특히 유명한 햄버거 체인인 '화이트 캐슬(White Castle)'의 슬라이더는 작고, 맛있으며, 뉴욕의 정취를 느낄 수 있는 대표적인 음식입니다. 다양한 토핑과 소스와 함께 즐길 수 있어 뉴욕의 빠른 음식 문화도 체험할 수 있습니다!\n",
      "도쿄: 도쿄에 가면 꼭 먹어야 할 음식으로 **스시**를 추천합니다. 특히, 신선한 생선과 다양한 해산물을 사용할 수 있는 도쿄에서는 옛날 스타일의 스시를 즐길 수 있는 곳이 많습니다. 츠키지 수산시장에서 신선한 스시를 맛보거나, 유명한 스시 전문점에서 셰프가 직접 만드는 스시를 경험해 보세요!\n",
      "방콕: 방콕에 가면 꼭 먹어야 할 음식은 **팩천(Pad Thai)**입니다. 태국의 대표적인 볶음국수인 팟타이는 새우, 두부, 숙주, 땅콩 등이 들어가고, 특유의 달콤하고 짭짤한 소스와 함께 제공됩니다. 길거리 음식으로도 쉽게 찾을 수 있고, 다양한 맛을 즐길 수 있는 꼭 맛봐야 할 요리입니다!\n",
      "로마: 로마에 가면 꼭 먹어야 할 음식은 \"카르보나라(Carbonara)\"입니다. 스파게티 카르보나라는 로마의 전통 파스타 요리로, 구운 판체타(또는 구아니야), 계란, 페코리노 치즈, 후추로 간단하게 조리됩니다. 로마를 방문할 때 이 정통 요리를 꼭 맛보세요!\n"
     ]
    }
   ],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import asyncio\n",
    "\n",
    "async_client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "async def get_food_recommendation(city):\n",
    "    print(f\"[{city}] 맛집 검색 시작...\")\n",
    "    response = await async_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"{city}에 가면 꼭 먹어야 할 음식 딱 한 가지만 추천해줘.\"}]\n",
    "    )\n",
    "    print(f\"[{city}] 검색 완료!\")\n",
    "    return f\"{city}: {response.choices[0].message.content}\"\n",
    "\n",
    "async def main():\n",
    "    cities = [\"서울\", \"파리\", \"뉴욕\", \"도쿄\", \"방콕\", \"로마\"]\n",
    "    tasks = [get_food_recommendation(c) for c in cities]\n",
    "    \n",
    "    # 여러 요청을 동시에(병렬로) 처리\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(\"\\n--- [여행자들을 위한 미식 가이드] ---\")\n",
    "    for r in results:\n",
    "        print(r)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logprobs - 확률 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "prompt = \"새로 오픈한 조용한 북카페 이름을 한글로 딱 하나만 추천해줘.\"\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    logprobs=True,\n",
    "    top_logprobs=3,\n",
    "    max_completion_tokens=50\n",
    ")\n",
    "\n",
    "content = response.choices[0].message.content\n",
    "logprobs_data = response.choices[0].logprobs.content\n",
    "\n",
    "print(f\"질문: {prompt}\")\n",
    "print(f\"답변: {content}\\n\")\n",
    "print(f\"{'Token':<15} | {'Probability':<12} | {'Top Alternatives'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for lp in logprobs_data:\n",
    "    prob = math.exp(lp.logprob) * 100\n",
    "    alternatives = [f\"{top.token}({math.exp(top.logprob)*100:.1f}%)\" for top in lp.top_logprobs]\n",
    "    print(f\"{lp.token:<15} | {prob:>10.2f}% | {', '.join(alternatives)}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
